{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as a woman you shouldnt complain about cleanin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2004, 1037, 2450, 2017, 5807, 2102, 1761...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy dats coldtyga dwn bad for cuffin dat hoe i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2879, 23755, 2015, 3147, 3723, 3654, 104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dawg you ever fuck a bitch and she sta to cry ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 4830, 27767, 2017, 2412, 6616, 1037, 774...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she look like a tranny</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2016, 2298, 2066, 1037, 25283, 4890, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the shit you hear about me might be true or it...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1996, 4485, 2017, 2963, 2055, 2033, 2453...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label  \\\n",
       "0  as a woman you shouldnt complain about cleanin...      0   \n",
       "1  boy dats coldtyga dwn bad for cuffin dat hoe i...      0   \n",
       "2  dawg you ever fuck a bitch and she sta to cry ...      0   \n",
       "3                             she look like a tranny      0   \n",
       "4  the shit you hear about me might be true or it...      0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [101, 2004, 1037, 2450, 2017, 5807, 2102, 1761...  \n",
       "1  [101, 2879, 23755, 2015, 3147, 3723, 3654, 104...  \n",
       "2  [101, 4830, 27767, 2017, 2412, 6616, 1037, 774...  \n",
       "3    [101, 2016, 2298, 2066, 1037, 25283, 4890, 102]  \n",
       "4  [101, 1996, 4485, 2017, 2963, 2055, 2033, 2453...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_pickle('../preprocessed/tweets_bert.pkl')\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "tweets = df['tweet'].values\n",
    "labels = df['label'].values\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(tweets)\n",
    "sequences = tokenizer.texts_to_sequences(tweets)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
