{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>denial of normal the con be asked to comment o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just by being able to tweet this insufferable ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is retarded you too cute to be single tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thought of a real badass mongol style declarat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afro american basho</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  denial of normal the con be asked to comment o...      1\n",
       "1  just by being able to tweet this insufferable ...      1\n",
       "2  that is retarded you too cute to be single tha...      1\n",
       "3  thought of a real badass mongol style declarat...      1\n",
       "4                                afro american basho      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/mendeley/HateSpeechDatasetBalanced.csv\")\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## libraries to be used\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using both count vectorizer and tfidf to analyze performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51000 50000\n"
     ]
    }
   ],
   "source": [
    "## check vocab size for reference, to help determine max features value for vectorizers \n",
    "\n",
    "vocab_file = '..\\\\..\\\\custom_bert_tokenizer_mendeley\\\\vocab.txt'\n",
    "with open(vocab_file, 'r', encoding='utf-8') as f:\n",
    "    vocab_size = sum(1 for _ in f)\n",
    "\n",
    "max_features = min(vocab_size + 1000, 60000)  #  allow some extra room for unseen data\n",
    "print(max_features, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the CountVectorizer\n",
    "count_vectorizer = CountVectorizer(max_features=max_features)  \n",
    "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
    "X_test_counts = count_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=max_features)  \n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bemne\\anaconda3\\envs\\al\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## train log regression model on counts vectorized dataset\n",
    "model_count = LogisticRegression()\n",
    "model_count.fit(X_train_counts, y_train)\n",
    "\n",
    "y_pred_counts = model_count.predict(X_test_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the log regression model on tfidf vectorized dataset\n",
    "model_tfidf = LogisticRegression()\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer - Accuracy: 0.833395306560899\n",
      "CountVectorizer - Precision: 0.8316946994935132\n",
      "CountVectorizer - Recall: 0.8392068979653189\n",
      "CountVectorizer - F1 Score: 0.8354339117008903\n",
      "CountVectorizer - ROC AUC: 0.8333494062581754\n"
     ]
    }
   ],
   "source": [
    "## evaluate model on count vectorizer \n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_counts = accuracy_score(y_test, y_pred_counts)\n",
    "precision_counts = precision_score(y_test, y_pred_counts, average='binary')\n",
    "recall_counts = recall_score(y_test, y_pred_counts, average='binary')\n",
    "f1_counts = f1_score(y_test, y_pred_counts, average='binary')\n",
    "roc_auc_counts = roc_auc_score(y_test, y_pred_counts)\n",
    "\n",
    "# Print metrics\n",
    "print(f'CountVectorizer - Accuracy: {accuracy_counts}')\n",
    "print(f'CountVectorizer - Precision: {precision_counts}')\n",
    "print(f'CountVectorizer - Recall: {recall_counts}')\n",
    "print(f'CountVectorizer - F1 Score: {f1_counts}')\n",
    "print(f'CountVectorizer - ROC AUC: {roc_auc_counts}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer - Accuracy: 0.8379124662590205\n",
      "TfidfVectorizer - Precision: 0.838142335567544\n",
      "TfidfVectorizer - Recall: 0.8406963556114292\n",
      "TfidfVectorizer - F1 Score: 0.8394174028720538\n",
      "TfidfVectorizer - ROC AUC: 0.8378904789314311\n"
     ]
    }
   ],
   "source": [
    "## evaluaate on tfidf vectorizer \n",
    "# Calculate metrics\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "precision_tfidf = precision_score(y_test, y_pred_tfidf, average='binary')\n",
    "recall_tfidf = recall_score(y_test, y_pred_tfidf, average='binary')\n",
    "f1_tfidf = f1_score(y_test, y_pred_tfidf, average='binary')\n",
    "roc_auc_tfidf = roc_auc_score(y_test, y_pred_tfidf)\n",
    "\n",
    "# Print metrics\n",
    "print(f'TfidfVectorizer - Accuracy: {accuracy_tfidf}')\n",
    "print(f'TfidfVectorizer - Precision: {precision_tfidf}')\n",
    "print(f'TfidfVectorizer - Recall: {recall_tfidf}')\n",
    "print(f'TfidfVectorizer - F1 Score: {f1_tfidf}')\n",
    "print(f'TfidfVectorizer - ROC AUC: {roc_auc_tfidf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis \n",
    "\n",
    "TfidfVectorizer is the better choice between the two this task. It achieves higher recall, F1 score, and ROC AUC, which are critical for effectively identifying hate speech tweets while minimizing false positives.\n",
    "\n",
    "## Dataset effects \n",
    "\n",
    "For reference, this was the best result we got from using the davidson dataset (with tfidf Vectorizer, on a customized token vocabulary)\n",
    "```\n",
    "TfidfVectorizer - Accuracy: 0.791958041958042\n",
    "TfidfVectorizer - Precision: 0.7568493150684932\n",
    "TfidfVectorizer - Recall: 0.8215613382899628\n",
    "TfidfVectorizer - F1 Score: 0.7878787878787878\n",
    "TfidfVectorizer - ROC AUC: 0.7936189529733642\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current model perfoms significantly better on this larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
